{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/21 17:48:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>leetcode_basic_joins</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f24d6f4a9a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window as W\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"leetcode_basic_joins\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "1. Customer Who Visited but Did Not Make Any Transactions\n",
    "https://leetcode.com/problems/customer-who-visited-but-did-not-make-any-transactions/description/?envType=study-plan-v2&envId=top-sql-50 \n",
    "\n",
    "Write a solution to find the IDs of the users who visited without making any transactions and the number of times they made these types of visits.\n",
    "Input: \n",
    "\n",
    "Visits\n",
    "+----------+-------------+\n",
    "| visit_id | customer_id |\n",
    "+----------+-------------+\n",
    "| 1        | 23          |\n",
    "| 2        | 9           |\n",
    "| 4        | 30          |\n",
    "| 5        | 54          |\n",
    "| 6        | 96          |\n",
    "| 7        | 54          |\n",
    "| 8        | 54          |\n",
    "+----------+-------------+\n",
    "Transactions\n",
    "+----------------+----------+--------+\n",
    "| transaction_id | visit_id | amount |\n",
    "+----------------+----------+--------+\n",
    "| 2              | 5        | 310    |\n",
    "| 3              | 5        | 300    |\n",
    "| 9              | 5        | 200    |\n",
    "| 12             | 1        | 910    |\n",
    "| 13             | 2        | 970    |\n",
    "+----------------+----------+--------+\n",
    "\n",
    "Output: \n",
    "+-------------+----------------+\n",
    "| customer_id | count_no_trans |\n",
    "+-------------+----------------+\n",
    "| 54          | 2              |\n",
    "| 30          | 1              |\n",
    "| 96          | 1              |\n",
    "+-------------+----------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_data = [(1, 23), (2, 9), (4, 30), (5, 54), (6, 96), (7, 54), (8, 54)]\n",
    "\n",
    "transactions_data = [(2, 5, 310), (3, 5, 300), (9, 5, 200), (12, 1, 910), (13, 2, 970)]\n",
    "\n",
    "# Create DataFrames\n",
    "visits_df = spark.createDataFrame(visits_data, [\"visit_id\", \"customer_id\"])\n",
    "transactions_df = spark.createDataFrame(\n",
    "    transactions_data, [\"transaction_id\", \"visit_id\", \"amount\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|customer_id|count_no_trans|\n",
      "+-----------+--------------+\n",
      "|         96|             1|\n",
      "|         54|             2|\n",
      "|         30|             1|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    visits_df.join(\n",
    "        transactions_df, on=visits_df.visit_id == transactions_df.visit_id, how=\"left\"\n",
    "    )\n",
    "    .filter(F.col(\"transaction_id\").isNull())\n",
    "    .groupBy(F.col(\"customer_id\"))\n",
    "    .agg(F.count(visits_df.visit_id).alias(\"count_no_trans\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a solution to find all dates' Id with higher temperatures compared to its previous dates (yesterday).\n",
      "Input:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+\n",
      "| id|recordDate|temperature|\n",
      "+---+----------+-----------+\n",
      "|  1|2015-01-01|         10|\n",
      "|  2|2015-01-02|         25|\n",
      "|  3|2015-01-03|         20|\n",
      "|  4|2015-01-04|         30|\n",
      "+---+----------+-----------+\n",
      "\n",
      "Output: \n",
      "+----+\n",
      "| id |\n",
      "+----+\n",
      "| 2  |\n",
      "| 4  |\n",
      "+----+      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Write a solution to find all dates' Id with higher temperatures compared to its previous dates (yesterday).\"\n",
    ")\n",
    "data = [\n",
    "    (1, \"2015-01-01\", 10),\n",
    "    (2, \"2015-01-02\", 25),\n",
    "    (3, \"2015-01-03\", 20),\n",
    "    (4, \"2015-01-04\", 30),\n",
    "]\n",
    "weather_df1 = spark.createDataFrame(data, [\"id\", \"recordDate\", \"temperature\"])\n",
    "weather_df2 = spark.createDataFrame(data, [\"id\", \"recordDate\", \"temperature\"])\n",
    "print(\"Input:\")\n",
    "weather_df1.show()\n",
    "\n",
    "print(\n",
    "    \"\"\"Output: \n",
    "+----+\n",
    "| id |\n",
    "+----+\n",
    "| 2  |\n",
    "| 4  |\n",
    "+----+      \n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  4|\n",
      "|  2|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather_df1.join(\n",
    "        weather_df2,\n",
    "        how=\"inner\",\n",
    "        on=weather_df1.recordDate == F.date_add(weather_df2.recordDate, -1),\n",
    "    )\n",
    "    .filter(weather_df2.temperature > weather_df1.temperature)\n",
    "    .select(weather_df2.id)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Time of Process per Machine\n",
      "There is a factory website that has several machines each running the same number of processes. Write a solution to find the average time each machine takes to complete a process.\n",
      "The time to complete a process is the 'end' timestamp minus the 'start' timestamp. The average time is calculated by the total time to complete every process on the machine divided by the number of processes that were run.\n",
      "The resulting table should have the machine_id along with the average time as processing_time, which should be rounded to 3 decimal places.\n",
      "Input: \n",
      "+----------+----------+-------------+---------+\n",
      "|machine_id|process_id|activity_type|timestamp|\n",
      "+----------+----------+-------------+---------+\n",
      "|         0|         0|        start|    0.712|\n",
      "|         0|         0|          end|     1.52|\n",
      "|         0|         1|        start|     3.14|\n",
      "|         0|         1|          end|     4.12|\n",
      "|         1|         0|        start|     0.55|\n",
      "|         1|         0|          end|     1.55|\n",
      "|         1|         1|        start|     0.43|\n",
      "|         1|         1|          end|     1.42|\n",
      "|         2|         0|        start|      4.1|\n",
      "|         2|         0|          end|    4.512|\n",
      "|         2|         1|        start|      2.5|\n",
      "|         2|         1|          end|      5.0|\n",
      "+----------+----------+-------------+---------+\n",
      "\n",
      "Output: \n",
      "+------------+-----------------+\n",
      "| machine_id | processing_time |\n",
      "+------------+-----------------+\n",
      "| 0          | 0.894           |\n",
      "| 1          | 0.995           |\n",
      "| 2          | 1.456           |\n",
      "+------------+-----------------+ \n",
      "Explanation: \n",
      "There are 3 machines running 2 processes each.\n",
      "Machine 0's average time is ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894\n",
      "Machine 1's average time is ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995\n",
      "Machine 2's average time is ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Average Time of Process per Machine\n",
    "There is a factory website that has several machines each running the same number of processes. Write a solution to find the average time each machine takes to complete a process.\n",
    "The time to complete a process is the 'end' timestamp minus the 'start' timestamp. The average time is calculated by the total time to complete every process on the machine divided by the number of processes that were run.\n",
    "The resulting table should have the machine_id along with the average time as processing_time, which should be rounded to 3 decimal places.\n",
    "Input: \"\"\")\n",
    "# Sample data\n",
    "activity_data = [\n",
    "    (0, 0, 'start', 0.712),\n",
    "    (0, 0, 'end', 1.520),\n",
    "    (0, 1, 'start', 3.140),\n",
    "    (0, 1, 'end', 4.120),\n",
    "    (1, 0, 'start', 0.550),\n",
    "    (1, 0, 'end', 1.550),\n",
    "    (1, 1, 'start', 0.430),\n",
    "    (1, 1, 'end', 1.420),\n",
    "    (2, 0, 'start', 4.100),\n",
    "    (2, 0, 'end', 4.512),\n",
    "    (2, 1, 'start', 2.500),\n",
    "    (2, 1, 'end', 5.000)\n",
    "]\n",
    "\n",
    "activity_df = spark.createDataFrame(activity_data, [\"machine_id\", \"process_id\", \"activity_type\", \"timestamp\"])\n",
    "activity_df.show()\n",
    "\n",
    "print(\"\"\"Output: \n",
    "+------------+-----------------+\n",
    "| machine_id | processing_time |\n",
    "+------------+-----------------+\n",
    "| 0          | 0.894           |\n",
    "| 1          | 0.995           |\n",
    "| 2          | 1.456           |\n",
    "+------------+-----------------+ \n",
    "Explanation: \n",
    "There are 3 machines running 2 processes each.\n",
    "Machine 0's average time is ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894\n",
    "Machine 1's average time is ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995\n",
    "Machine 2's average time is ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|machine_id|processing_time |\n",
      "+----------+----------------+\n",
      "|         0|           0.894|\n",
      "|         1|           0.995|\n",
      "|         2|           1.456|\n",
      "+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Group By Aproach\n",
    "(\n",
    "    activity_df.groupBy(F.col(\"machine_id\"))\n",
    "    .agg(\n",
    "        F.sum(\n",
    "            F.when(F.col(\"activity_type\") == \"start\", F.col(\"timestamp\")).otherwise(0)\n",
    "        ).alias(\"start_timestamp\"),\n",
    "        F.sum(\n",
    "            F.when(F.col(\"activity_type\") == \"end\", F.col(\"timestamp\")).otherwise(0)\n",
    "        ).alias(\"end_timestamp\"),\n",
    "        F.count(\n",
    "            F.when(F.col(\"activity_type\") == \"start\", F.col(\"timestamp\")).otherwise(\n",
    "                None\n",
    "            )\n",
    "        ).alias(\"no_of_process\"),\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"machine_id\"),\n",
    "        F.round(\n",
    "            (F.col(\"end_timestamp\") - F.col(\"start_timestamp\"))\n",
    "            / F.col(\"no_of_process\"),\n",
    "            3,\n",
    "        ).alias(\"processing_time \"),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
